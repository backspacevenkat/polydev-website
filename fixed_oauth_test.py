#!/usr/bin/env python3
"""
Fixed OAuth test using port 1455 (like real OpenAI Codex CLI)
"""

import urllib.parse
import secrets
import base64
import hashlib
from http.server import HTTPServer, BaseHTTPRequestHandler
import threading
import time

class FixedCallbackHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        print(f"\nğŸ¯ CALLBACK RECEIVED: {self.path}")
        
        if 'code=' in self.path:
            # Extract auth code
            code = self.path.split('code=')[1].split('&')[0]
            self.server.auth_code = code
            print(f"âœ… AUTHORIZATION CODE: {code[:30]}...")
            
            self.send_response(200)
            self.send_header('Content-type', 'text/html')
            self.end_headers()
            
            success_html = """
            <!DOCTYPE html>
            <html>
            <head><title>Cross-LLM Bridge - OAuth Success</title></head>
            <body style="font-family: Arial; text-align: center; margin-top: 100px;">
                <h1 style="color: green;">ğŸ‰ OAuth Authentication Successful!</h1>
                <h2>Cross-LLM Bridge</h2>
                <p><strong>Authorization code received successfully.</strong></p>
                <p>You can close this window and return to the terminal.</p>
                <div style="background: #f0f0f0; padding: 20px; margin: 20px; border-radius: 5px;">
                    <h3>What happens next:</h3>
                    <p>1. âœ… Authorization code captured</p>
                    <p>2. ğŸ”„ Exchange code for access token</p>
                    <p>3. ğŸš€ Ready for Cross-LLM communication!</p>
                </div>
            </body>
            </html>
            """
            self.wfile.write(success_html.encode())
        else:
            print(f"âŒ No auth code in callback: {self.path}")
            self.send_response(400)
            self.send_header('Content-type', 'text/html')
            self.end_headers()
            self.wfile.write(b'<h1>OAuth Error: No authorization code</h1>')
    
    def log_message(self, format, *args):
        pass

def main():
    print("Cross-LLM Bridge - Fixed OAuth Test (Port 1455)")
    print("===============================================")
    
    # Check if port 1455 is available
    import socket
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    result = sock.connect_ex(('localhost', 1455))
    sock.close()
    
    if result == 0:
        print("âŒ Port 1455 is in use!")
        print("ğŸ”§ Kill the process: lsof -i :1455 && kill -9 <PID>")
        return False
    
    # Start server on port 1455 (like real OpenAI CLI)
    server = HTTPServer(("localhost", 1455), FixedCallbackHandler)
    server.auth_code = None
    
    # Start in background
    thread = threading.Thread(target=server.serve_forever)
    thread.daemon = True
    thread.start()
    
    print("âœ… Callback server running on localhost:1455")
    print("ğŸ“ Using OpenAI Codex CLI standard port")
    
    # Generate PKCE (same as real implementation)
    verifier = base64.urlsafe_b64encode(secrets.token_bytes(32)).decode('utf-8').rstrip('=')
    challenge = base64.urlsafe_b64encode(hashlib.sha256(verifier.encode()).digest()).decode('utf-8').rstrip('=')
    
    # Build OAuth URL with correct port
    params = {
        'response_type': 'code',
        'client_id': 'app_EMoamEEZ73f0CkXaXp7hrann',
        'redirect_uri': 'http://localhost:1455/auth/callback',  # Changed to 1455!
        'scope': 'openid profile email offline_access',
        'code_challenge': challenge,
        'code_challenge_method': 'S256',
        'state': secrets.token_urlsafe(16)
    }
    
    url = 'https://auth.openai.com/authorize?' + urllib.parse.urlencode(params)
    
    print(f"\nğŸ”— FIXED OAUTH URL (Port 1455):")
    print(url)
    print(f"\nğŸ“ MANUAL TEST:")
    print(f"1. Copy the OAuth URL above")
    print(f"2. Open it in your browser")
    print(f"3. Log in to OpenAI/ChatGPT")
    print(f"4. Authorize the application")
    print(f"5. Watch this terminal for callback")
    print(f"\nğŸ” Key Changes:")
    print(f"   - Using port 1455 (OpenAI CLI standard)")
    print(f"   - Proper PKCE implementation")
    print(f"   - Enhanced callback handling")
    
    # Wait for callback (2 minutes)
    print(f"\nâ³ Waiting 120 seconds for OAuth callback...")
    print(f"ğŸ›‘ Press Ctrl+C to stop")
    
    start_time = time.time()
    while server.auth_code is None and (time.time() - start_time) < 120:
        time.sleep(1)
        
        # Show progress every 30 seconds
        elapsed = int(time.time() - start_time)
        if elapsed > 0 and elapsed % 30 == 0:
            print(f"â° Still waiting... ({elapsed}s elapsed)")
    
    if server.auth_code:
        print(f"\nğŸ‰ SUCCESS! OAuth flow completed!")
        print(f"âœ… Authorization code: {server.auth_code[:40]}...")
        print(f"âœ… Code verifier: {verifier[:20]}...")
        print(f"âœ… Cross-LLM Bridge OAuth is working!")
        print(f"\nğŸ“ Next: Exchange code for access token")
        result = True
    else:
        print(f"\nâ° TIMEOUT - No OAuth callback received")
        print(f"\nğŸ”§ If this still fails, the issue might be:")
        print(f"   - OpenAI client_id is invalid/restricted")
        print(f"   - OpenAI doesn't allow localhost redirects")
        print(f"   - Browser security blocking the redirect")
        print(f"   - Need to register app with OpenAI first")
        result = False
    
    server.shutdown()
    return result

if __name__ == "__main__":
    try:
        success = main()
        if success:
            print(f"\nğŸŠ READY FOR CROSS-LLM BRIDGE INTEGRATION!")
        else:
            print(f"\nğŸ”§ OAuth still needs debugging")
    except KeyboardInterrupt:
        print(f"\nğŸ›‘ Test cancelled by user")
    except Exception as e:
        print(f"\nâŒ Error: {e}")